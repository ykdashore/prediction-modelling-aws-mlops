{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be68997",
   "metadata": {},
   "source": [
    "## Training Regression Model for Restaurant Revenue Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b31f7a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "file_handler = logging.FileHandler('app.log')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.info('This is an info message')\n",
    "\n",
    "# Kaggle and S3 configuration\n",
    "KAGGLE_DATASET = 'anthonytherrien/restaurant-revenue-prediction-dataset'\n",
    "S3_BUCKET = 'restaurant-revenue'\n",
    "S3_PREFIX = 'restaurant-revenue-prediction'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60063bd",
   "metadata": {},
   "source": [
    "### Load data from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2c30bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to download dataset from Kaggle\n",
    "def download_kaggle_dataset(dataset_name, download_path):\n",
    "    logger.info(\"Downloading dataset from Kaggle...\")\n",
    "    try:\n",
    "        os.system(f'kaggle datasets download -d {dataset_name} -p {download_path} --unzip')\n",
    "        logger.info(\"Dataset downloaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to download dataset from Kaggle: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31dcf044",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to load dataset\n",
    "def load_dataset(file_path):\n",
    "    logger.info(\"Loading dataset...\")\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        logger.info(\"Dataset loaded successfully.\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load dataset: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a461aa0e",
   "metadata": {},
   "source": [
    "### Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b33666eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to preprocess and clean data\n",
    "def preprocess_data(df, target_column=None, is_training=True, preprocessor=None):\n",
    "    logger.info(\"Preprocessing data...\")\n",
    "    try:\n",
    "        df = df.drop(\"Name\", axis=1)\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        if is_training:\n",
    "            X = df.drop(columns=[target_column])\n",
    "            y = df[target_column]\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', StandardScaler(), ['Rating', 'Seating Capacity', 'Average Meal Price', 'Marketing Budget', 'Social Media Followers', 'Chef Experience Years', 'Number of Reviews', 'Avg Review Length', 'Ambience Score', 'Service Quality Score', 'Weekend Reservations', 'Weekday Reservations']),\n",
    "                    ('cat', OneHotEncoder(), ['Location', 'Cuisine', 'Parking Availability'])\n",
    "                ],\n",
    "                remainder='passthrough'\n",
    "            )\n",
    "            X = preprocessor.fit_transform(X)\n",
    "            logger.info(\"Data preprocessed successfully (training).\")\n",
    "            return X, y, preprocessor\n",
    "        else:\n",
    "            X = preprocessor.transform(df)\n",
    "            logger.info(\"Data preprocessed successfully (prediction).\")\n",
    "            return X, preprocessor\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to preprocess data: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1083df",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cecd7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to split data\n",
    "def split_data(X, y):\n",
    "    logger.info(\"Splitting data...\")\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        logger.info(\"Data split successfully.\")\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to split data: {e}\")\n",
    "        return None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e83bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to train models\n",
    "def train_models(X_train, y_train):\n",
    "    logger.info(\"Training models...\")\n",
    "    try:\n",
    "        rf_model = RandomForestRegressor(random_state=42)\n",
    "        xgb_model = XGBRegressor(random_state=42)\n",
    "        \n",
    "        rf_model.fit(X_train, y_train)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        \n",
    "        logger.info(\"Models trained successfully.\")\n",
    "        return rf_model, xgb_model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to train models: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77b6b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    logger.info(\"Evaluating models...\")\n",
    "    try:\n",
    "        for name, model in models.items():\n",
    "            predictions = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            logger.info(f\"{name} Model Mean Squared Error: {mse}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to evaluate models: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7415db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to save model to S3\n",
    "def save_model_to_s3(model, model_name, bucket, prefix):\n",
    "    logger.info(f\"Saving model {model_name} to S3...\")\n",
    "    try:\n",
    "        model_path = f\"/tmp/{model_name}.joblib\"\n",
    "        joblib.dump(model, model_path)\n",
    "        s3_client = boto3.client('s3')\n",
    "        s3_client.upload_file(model_path, bucket, f\"{prefix}/{model_name}.joblib\")\n",
    "        logger.info(f\"Model {model_name} saved to S3 successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save model to S3: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f35a37a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to save preprocessor to S3\n",
    "def save_preprocessor_to_s3(preprocessor, preprocessor_name, bucket, prefix):\n",
    "    logger.info(f\"Saving preprocessor {preprocessor_name} to S3...\")\n",
    "    try:\n",
    "        preprocessor_path = f\"/tmp/{preprocessor_name}.joblib\"\n",
    "        joblib.dump(preprocessor, preprocessor_path)\n",
    "        s3_client = boto3.client('s3')\n",
    "        s3_client.upload_file(preprocessor_path, bucket, f\"{prefix}/{preprocessor_name}.joblib\")\n",
    "        logger.info(f\"Preprocessor {preprocessor_name} saved to S3 successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save preprocessor to S3: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78e69618",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to load model from S3\n",
    "def load_model_from_s3(model_name, bucket, prefix):\n",
    "    logger.info(f\"Loading model {model_name} from S3...\")\n",
    "    try:\n",
    "        s3_client = boto3.client('s3')\n",
    "        model_path = f\"/tmp/{model_name}.joblib\"\n",
    "        s3_client.download_file(bucket, f\"{prefix}/{model_name}.joblib\", model_path)\n",
    "        model = joblib.load(model_path)\n",
    "        logger.info(f\"Model {model_name} loaded successfully.\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load model from S3: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bf1346",
   "metadata": {},
   "source": [
    "### Load preprocessor for feature consistency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ad27ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to load preprocessor from S3\n",
    "def load_preprocessor_from_s3(preprocessor_name, bucket, prefix):\n",
    "    logger.info(f\"Loading preprocessor {preprocessor_name} from S3...\")\n",
    "    try:\n",
    "        s3_client = boto3.client('s3')\n",
    "        preprocessor_path = f\"/tmp/{preprocessor_name}.joblib\"\n",
    "        s3_client.download_file(bucket, f\"{prefix}/{preprocessor_name}.joblib\", preprocessor_path)\n",
    "        preprocessor = joblib.load(preprocessor_path)\n",
    "        logger.info(f\"Preprocessor {preprocessor_name} loaded successfully.\")\n",
    "        return preprocessor\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load preprocessor from S3: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "583297eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/anthonytherrien/restaurant-revenue-prediction-dataset\n",
      "License(s): CC-BY-SA-4.0\n",
      "Downloading restaurant-revenue-prediction-dataset.zip to .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339k/339k [00:00<00:00, 749kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Set AWS credentials as environment variables\n",
    "    # os.environ['AWS_ACCESS_KEY_ID'] = 'your-access-key-id'\n",
    "    # os.environ['AWS_SECRET_ACCESS_KEY'] = 'your-secret-access-key'\n",
    "    # os.environ['AWS_DEFAULT_REGION'] = 'your-default-region'\n",
    "\n",
    "    \n",
    "    # Download dataset from Kaggle\n",
    "    download_path = './'\n",
    "    download_kaggle_dataset(KAGGLE_DATASET, download_path)\n",
    "\n",
    "    # Load dataset\n",
    "    file_path = os.path.join(download_path, 'restaurant_data.csv')\n",
    "    data = load_dataset(file_path)\n",
    "\n",
    "    # Preprocess data\n",
    "    if data is not None:\n",
    "        X, y, preprocessor = preprocess_data(data, target_column='Revenue', is_training=True)\n",
    "\n",
    "    # Split data\n",
    "    if X is not None and y is not None:\n",
    "        X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "        # Train models\n",
    "        if X_train is not None and y_train is not None:\n",
    "            rf_model, xgb_model = train_models(X_train, y_train)\n",
    "\n",
    "            # Evaluate models\n",
    "            if rf_model is not None and xgb_model is not None:\n",
    "                models = {'Random Forest': rf_model, 'XGBoost': xgb_model}\n",
    "                evaluate_models(models, X_test, y_test)\n",
    "\n",
    "                # Save models and preprocessor to S3\n",
    "                save_model_to_s3(rf_model, 'random_forest_model', S3_BUCKET, S3_PREFIX)\n",
    "                save_model_to_s3(xgb_model, 'xgboost_model', S3_BUCKET, S3_PREFIX)\n",
    "                save_preprocessor_to_s3(preprocessor, 'preprocessor', S3_BUCKET, S3_PREFIX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212ac7f6",
   "metadata": {},
   "source": [
    "## Example code to load model and run the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "589c8345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Prediction: [310169.3862]\n",
      "XGBoost Prediction: [312052.03]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set AWS credentials as environment variables\n",
    "    # os.environ['AWS_ACCESS_KEY_ID'] = 'your-access-key-id'\n",
    "    # os.environ['AWS_SECRET_ACCESS_KEY'] = 'your-secret-access-key'\n",
    "    # os.environ['AWS_DEFAULT_REGION'] = 'your-default-region'\n",
    "\n",
    "\n",
    "    # Load the models and preprocessor from S3\n",
    "    rf_model = load_model_from_s3('random_forest_model', S3_BUCKET, S3_PREFIX)\n",
    "    xgb_model = load_model_from_s3('xgboost_model', S3_BUCKET, S3_PREFIX)\n",
    "    preprocessor = load_preprocessor_from_s3('preprocessor', S3_BUCKET, S3_PREFIX)\n",
    "\n",
    "    if rf_model and xgb_model and preprocessor:\n",
    "        # Prepare new data for prediction (Example data)\n",
    "        new_data = pd.DataFrame({\n",
    "            'Name': ['Example Restaurant'],\n",
    "            'Location': ['Downtown'],\n",
    "            'Cuisine': ['Italian'],\n",
    "            'Rating': [4.5],\n",
    "            'Seating Capacity': [50],\n",
    "            'Average Meal Price': [20.0],\n",
    "            'Marketing Budget': [5000],\n",
    "            'Social Media Followers': [1000],\n",
    "            'Chef Experience Years': [15],\n",
    "            'Number of Reviews': [150],\n",
    "            'Avg Review Length': [200],\n",
    "            'Ambience Score': [8.5],\n",
    "            'Service Quality Score': [9.0],\n",
    "            'Parking Availability': ['Yes'],\n",
    "            'Weekend Reservations': [30],\n",
    "            'Weekday Reservations': [20]\n",
    "        })\n",
    "\n",
    "        # Preprocess the new data\n",
    "        preprocessed_data, _ = preprocess_data(new_data, is_training=False, preprocessor=preprocessor)\n",
    "\n",
    "        if preprocessed_data is not None:\n",
    "            # Make predictions with the loaded models\n",
    "            rf_prediction = rf_model.predict(preprocessed_data)\n",
    "            xgb_prediction = xgb_model.predict(preprocessed_data)\n",
    "\n",
    "            logger.info(f\"Random Forest Prediction: {rf_prediction}\")\n",
    "            logger.info(f\"XGBoost Prediction: {xgb_prediction}\")\n",
    "\n",
    "            # Print predictions\n",
    "            print(f\"Random Forest Prediction: {rf_prediction}\")\n",
    "            print(f\"XGBoost Prediction: {xgb_prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b0c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
